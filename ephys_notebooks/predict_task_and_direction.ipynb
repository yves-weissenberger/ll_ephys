{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "import sys\n",
    "import os\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.ndimage as ndi\n",
    "import scipy.stats as stt\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "#optional for nicer plots\n",
    "import seaborn\n",
    "clrs = seaborn.color_palette(n_colors=6)\n",
    "seaborn.set(style='ticks',font_scale=2)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.manifold import MDS\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import LeavePOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UPDATE THE PATH BELOW TO THE CODE FOLDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"/Users/yves/Desktop/retreat_data_dir/code/\")\n",
    "from mecll.task import plot_activity_on_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_across_task_plane_ccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-07-27_39955_ks25\n"
     ]
    }
   ],
   "source": [
    "#These are the times (in units of the behaviour system bin running @1000Hz) at which spikes occurred\n",
    "\n",
    "selected_session = 1\n",
    "\n",
    "all_data_dir = '/Users/yves/Desktop/retreat_data_dir/data/'\n",
    "all_data_folders = sorted([i for i in os.listdir(all_data_dir) if 'ks25' in i])\n",
    "print(all_data_folders[selected_session])\n",
    "root_dir = os.path.join(all_data_dir,all_data_folders[selected_session])\n",
    "spkT = np.load(os.path.join(root_dir,'spkT_task.npy'))\n",
    "\n",
    "\n",
    "#This array is the same shape as spkT but shows which cluster each of the spikes in spkT belongs to\n",
    "spkC = np.load(os.path.join(root_dir,'spkC_task.npy'))\n",
    "\n",
    "#This is basically a big table (you can open it in excel) which contains\n",
    "#relevant information about each time the animal poked one of the ports\n",
    "task_event_df = pd.read_csv(os.path.join(root_dir,'task_event_table.csv'),index_col=0)\n",
    "\n",
    "#\n",
    "response_table = np.load(os.path.join(root_dir,'neuron_response_table.npy'))\n",
    "#alternatively to change the time window\n",
    "\n",
    "\n",
    "#not all cluster in spkC correspond to single units. Single units is an array of the clusters that are single units\n",
    "single_units = np.load(os.path.join(root_dir,'single_units.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loop loop\n"
     ]
    }
   ],
   "source": [
    "graph_type0 = task_event_df.loc[task_event_df['task_nr']==0]['graph_type'].values[0]\n",
    "graph_type1 = task_event_df.loc[task_event_df['task_nr']==1]['graph_type'].values[0]\n",
    "\n",
    "seq0 = np.array(eval(task_event_df.loc[task_event_df['task_nr']==0]['current_sequence'].values[0]))\n",
    "seq1 = np.array(eval(task_event_df.loc[task_event_df['task_nr']==1]['current_sequence'].values[0]))\n",
    "print(graph_type0,graph_type1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_transitions(seq0: np.ndarray,seq1: np.ndarray):\n",
    "    \n",
    "    test_seq1 = []\n",
    "    for ix,i in enumerate(seq1):\n",
    "        #print(seq0[(np.where(seq0==i)[0]-1)%9],seq0[(np.where(seq0==i)[0])%9],seq1[(ix-1)%9],seq1[(ix)%9])\n",
    "        if seq0[(np.where(seq0==i)[0]-1)%9]!=seq1[(ix-1)%9]:\n",
    "            test_seq1.append(1)\n",
    "        else:\n",
    "            #print(seq1[ix])\n",
    "            test_seq1.append(0)\n",
    "\n",
    "    test_seq1 = np.array(test_seq1)\n",
    "    return test_seq1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(selected_session):\n",
    "    all_data_dir = '/Users/yves/Desktop/retreat_data_dir/data/'\n",
    "    all_data_folders = sorted([i for i in os.listdir(all_data_dir) if 'ks25' in i])\n",
    "    root_dir = os.path.join(all_data_dir,all_data_folders[selected_session])\n",
    "    spkT = np.load(os.path.join(root_dir,'spkT_task.npy'))\n",
    "\n",
    "\n",
    "    #This array is the same shape as spkT but shows which cluster each of the spikes in spkT belongs to\n",
    "    spkC = np.load(os.path.join(root_dir,'spkC_task.npy'))\n",
    "\n",
    "    #This is basically a big table (you can open it in excel) which contains\n",
    "    #relevant information about each time the animal poked one of the ports\n",
    "    task_event_df = pd.read_csv(os.path.join(root_dir,'task_event_table.csv'),index_col=0)\n",
    "\n",
    "    #\n",
    "    response_table = np.load(os.path.join(root_dir,'neuron_response_table.npy'))\n",
    "    #alternatively to change the time window\n",
    "\n",
    "\n",
    "    #not all cluster in spkC correspond to single units. Single units is an array of the clusters that are single units\n",
    "    single_units = np.load(os.path.join(root_dir,'single_units.npy'))\n",
    "    \n",
    "    \n",
    "    seq0 = np.array(eval(task_event_df.loc[task_event_df['task_nr']==0]['current_sequence'].values[0]))\n",
    "    seq1 = np.array(eval(task_event_df.loc[task_event_df['task_nr']==1]['current_sequence'].values[0]))\n",
    "    \n",
    "    \n",
    "    graph_type0 = task_event_df.loc[task_event_df['task_nr']==0]['graph_type'].values[0]\n",
    "    graph_type1 = task_event_df.loc[task_event_df['task_nr']==0]['graph_type'].values[0]\n",
    "    \n",
    "    firing_rate_maps = get_task_responses(task_event_df,response_table)\n",
    "    \n",
    "    return firing_rate_maps, task_event_df, (seq0,seq1,graph_type0,graph_type1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.unique(task_event_df['graph_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq0 = np.array(eval(task_event_df.loc[task_event_df['task_nr']==0]['current_sequence'].values[0]))\n",
    "seq1 = np.array(eval(task_event_df.loc[task_event_df['task_nr']==1]['current_sequence'].values[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_type0 = task_event_df.loc[task_event_df['task_nr']==0]['graph_type'].values[0]\n",
    "graph_type1 = task_event_df.loc[task_event_df['task_nr']==0]['graph_type'].values[0]\n",
    "\n",
    "seq0 = np.array(eval(task_event_df.loc[task_event_df['task_nr']==0]['current_sequence'].values[0]))\n",
    "seq1 = np.array(eval(task_event_df.loc[task_event_df['task_nr']==1]['current_sequence'].values[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_task_responses(task_event_df,response_table):\n",
    "    \"\"\" \n",
    "    Use the columns of the task_event_df to filter neural activity. \n",
    "    In this example build separate firing rate maps for each of the\n",
    "    tasks, selecting only trials where subjects poked the correct poke.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    n_neurons = response_table.shape[1]\n",
    "    n_ports = 9\n",
    "    n_tasks = 2\n",
    "    n_direction = 2\n",
    "    \n",
    "    #set variables to nan to not confuse missing data for no responses\n",
    "    firing_rate_maps = np.zeros([n_neurons,n_ports,n_tasks,n_direction]) + np.nan\n",
    "    \n",
    "    #for each task\n",
    "    for task in [0,1]:\n",
    "        \n",
    "        for port in range(n_ports):  #for each port\n",
    "            \n",
    "            for dix,direction in enumerate(np.unique(task_event_df['direction'].values)):\n",
    "\n",
    "                #Select indices of pokes where...\n",
    "                table_index = task_event_df.loc[(task_event_df['task_nr']==task) &  #task_nr was task\n",
    "                                                (task_event_df['correct']==True) &  #the poke was to the correct port\n",
    "                                                (task_event_df['port']==port) &       #the port poked was port\n",
    "                                                (task_event_df['direction']==direction)\n",
    "                                               ].index           \n",
    "                #print(len(table_index))\n",
    "                #get the average\n",
    "                firing_rate_maps[:,int(port),int(task),dix] = np.nanmean(response_table[table_index],axis=0)\n",
    "    return firing_rate_maps\n",
    "                                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "firing_rate_maps = get_task_responses(task_event_df,response_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neurons, n_ports, n_tasks, n_directions = firing_rate_maps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spatial_map  = np.nanmean(firing_rate_maps,axis=(2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mds_frm = firing_rate_maps - spatial_map[:,:,None,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "def fit_svm_classify_task(X_train: np.ndarray, y_train: np.ndarray,\n",
    "                          X_test: np.ndarray, y_test: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    svm = SVC(kernel='linear')\n",
    "    svm.fit(X_train.T,y_train)\n",
    "    return np.mean(svm.predict(X_test.T)==y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_task_train_test(task_X: np.ndarray,\n",
    "                           train_fraction: float=0.8, rnd_seed=None\n",
    "                           )-> Tuple[np.ndarray, np.ndarray]:\n",
    "    \n",
    "    \n",
    "    n_ports1 = task_X.shape[1]\n",
    "        \n",
    "    np.random.seed(rnd_seed)\n",
    "    \n",
    "    perm_task1 = np.random.permutation(np.arange(n_ports1))\n",
    "    \n",
    "    n_train1 = int(np.floor(train_fraction*n_ports1))\n",
    "    \n",
    "    train_X, test_X = task_X[:,perm_task1[:n_train1]], task_X[:,perm_task1[n_train1:]]\n",
    "    \n",
    "    return train_X, test_X\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(262, 9, 2)"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frm_task.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "task1_dir1 = np.logical_not(np.isnan(frm_task1[0,:,0]))\n",
    "task1_dir2 = np.logical_not(np.isnan(frm_task1[0,:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these firing rate maps are sorted by port NOT BY TASK\n",
    "frm_task1 = firing_rate_maps[:,:,1]\n",
    "frm_task2 = firing_rate_maps[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_valid_pokes_index_by_direction(frm_task: np.ndarray) -> Tuple[np.ndarray,np.ndarray]:\n",
    "\n",
    "    #\n",
    "    task_dir1 = np.where(np.logical_not(np.isnan(np.sum(frm_task,axis=0)[:,0])))[0]\n",
    "    task_dir2 = np.where(np.logical_not(np.isnan(np.sum(frm_task,axis=0)[:,1])))[0]\n",
    "\n",
    "    \n",
    "    return task_dir1, task_dir2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "task1_dir1, task1_dir2 = get_valid_pokes_index_by_direction(frm_task1)\n",
    "task2_dir1, task2_dir2 = get_valid_pokes_index_by_direction(frm_task2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_task_X(frm_task: np.ndarray, task_dir1: np.ndarray,\n",
    "               task_dir2: np.ndarray) -> np.ndarray:\n",
    "    \n",
    "    task_X = np.hstack([frm_task[:,task_dir1,0],\n",
    "                        frm_task[:,task_dir2,1]  \n",
    "    ])\n",
    "\n",
    "\n",
    "    return task_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8])"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task1_dir2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "task1_dir1, task1_dir2 = get_valid_pokes_index_by_direction(frm_task1)\n",
    "task2_dir1, task2_dir2 = get_valid_pokes_index_by_direction(frm_task2)\n",
    "\n",
    "\n",
    "task1_X = get_task_X(frm_task1, task1_dir1, task1_dir2)\n",
    "task2_X = get_task_X(frm_task2, task2_dir1, task2_dir2)\n",
    "\n",
    "\n",
    "train1_X, test1_X = create_task_train_test(task1_X)\n",
    "train2_X, test2_X = create_task_train_test(task2_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "task1_X = get_task_X(frm_task1, task1_dir1, task1_dir2)\n",
    "task2_X = get_task_X(frm_task2, task2_dir1, task2_dir2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(np.isfinite(task2_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_task_train_test(task_X: np.ndarray,\n",
    "                           train_fraction: float=0.8, rnd_seed=None\n",
    "                           )-> Tuple[np.ndarray, np.ndarray]:\n",
    "    \n",
    "    \n",
    "    n_ports1 = task_X.shape[1]\n",
    "        \n",
    "    np.random.seed(rnd_seed)\n",
    "    \n",
    "    perm_task1 = np.random.permutation(np.arange(n_ports1))\n",
    "    \n",
    "    n_train1 = int(np.floor(train_fraction*n_ports1))\n",
    "    \n",
    "    train_X, test_X = task_X[:,perm_task1[:n_train1]], task_X[:,perm_task1[n_train1:]]\n",
    "    \n",
    "    # check that order correctly determined\n",
    "    assert(np.allclose(train_X[:,0],task_X[:,perm_task1[0]]))\n",
    "    \n",
    "    # and that no funky duplication is going on\n",
    "    assert(np.sum(train_X,axis=0).shape[0]==len(np.unique(np.sum(train_X,axis=0))))\n",
    "    \n",
    "    return train_X, test_X\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(np.sum(train_X,axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(262, 12)"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(np.isfinite(train2_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_features_and_labels(X1: np.ndarray, X2: np.ndarray,\n",
    "                              ) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"X1.shape=(n_features, n_samples)\"\"\"\n",
    "    X = np.hstack([X1,X2])\n",
    "    y = np.concatenate([np.ones(X1.shape[1]),\n",
    "                              np.zeros([X2.shape[1]])\n",
    "                             ])\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "session_index:7"
     ]
    }
   ],
   "source": [
    "mu = []\n",
    "    \n",
    "for session_ix in range(4,8):\n",
    "    sys.stdout.write(\"\\rsession_index:{}\".format(session_ix))\n",
    "    sys.stdout.flush()\n",
    "    tmp_mu = []\n",
    "    for _ in range(50):\n",
    "\n",
    "        firing_rate_maps,_,_ = load_data(session_ix)\n",
    "        frm_task1 = firing_rate_maps[:,:,1]\n",
    "        frm_task2 = firing_rate_maps[:,:,0]\n",
    "\n",
    "        task1_dir1, task1_dir2 = get_valid_pokes_index_by_direction(frm_task1)\n",
    "        task2_dir1, task2_dir2 = get_valid_pokes_index_by_direction(frm_task2)\n",
    "\n",
    "\n",
    "        task1_X = get_task_X(frm_task1, task1_dir1, task1_dir2)\n",
    "        task2_X = get_task_X(frm_task2, task2_dir1, task2_dir2)\n",
    "\n",
    "\n",
    "        train1_X, test1_X = create_task_train_test(task1_X,rnd_seed=None)\n",
    "        train2_X, test2_X = create_task_train_test(task2_X,rnd_seed=None)\n",
    "\n",
    "        X_train, y_train = build_features_and_labels(train1_X,train2_X)\n",
    "        X_test, y_test = build_features_and_labels(test1_X,test2_X)\n",
    "\n",
    "\n",
    "        tmp_mu.append(fit_svm_classify_task(X_train,y_train,X_test,y_test))\n",
    "#                                        ))\n",
    "    mu.append(tmp_mu.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.760625"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.760625"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(np.isfinite(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_svm_classify_task(X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "[2]\n"
     ]
    }
   ],
   "source": [
    "valid_ix = np.where(~np.isnan(np.sum(firing_rate_maps,axis=(0,2,3))))[0]\n",
    "\n",
    "real_acoss_task_fit = np.abs(get_svm_fit_across_task(frm_task,frm_task2,\n",
    "                                                     valid_ix,\n",
    "                                                     overlapping_ports,\n",
    "                                                     do_shuffle=False)\n",
    "                             -.5)\n",
    "permutation_fits = [np.abs(get_svm_fit_across_task(frm_task,frm_task2,\n",
    "                                            valid_ix,\n",
    "                                            overlapping_ports,\n",
    "                                            do_shuffle=True) -.5)\n",
    "                    for _ in range(500)]\n",
    "                          \n",
    "#mean_perm_fits = [np.mean(i) for i in permutation_fits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.1"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stt.percentileofscore(permutation_fits,real_acoss_task_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_acoss_task_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now do the same but separating by direction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
